# wait for ssh connection
- hosts: all
  name: Wait for SSH connection
  gather_facts: false
  roles:
    - wait_ssh

# common setup phase
- hosts: all
  name: Common Setup
  become: true
  roles:
    - common

- hosts: bgp_router
  name: BIRD Setup
  become: true
  roles:
    - bird

# containerd setup phase
- hosts: cloud_servers
  name: Containerd Setup
  become: true
  roles:
    - containerd

# interface setup phase
- hosts: control_plane
  name: Netplan setup (control_plane)
  any_errors_fatal: true
  roles:
    - role: mrlesmithjr.netplan
      become: true
      netplan_remove_existing: false
      netplan_enabled: true
      netplan_config_file: /etc/netplan/60-ansible-config.yaml
      netplan_renderer: networkd
      netplan_configuration:
        network:
          version: 2
          ethernets:
            eth1:
              addresses:
                - 192.168.100.1{{groups["control_plane"].index(inventory_hostname)}}/24

- hosts: worker_node
  name: Netplan setup (worker_node)
  any_errors_fatal: true
  roles:
    - role: mrlesmithjr.netplan
      become: true
      netplan_remove_existing: false
      netplan_enabled: true
      netplan_config_file: /etc/netplan/60-ansible-config.yaml
      netplan_renderer: networkd
      netplan_configuration:
        network:
          version: 2
          ethernets:
            eth1:
              addresses:
                - 192.168.100.2{{groups["worker_node"].index(inventory_hostname)}}/24

- hosts: lb
  name: Netplan setup (lb)
  any_errors_fatal: true
  roles:
    - role: mrlesmithjr.netplan
      become: true
      netplan_remove_existing: false
      netplan_enabled: true
      netplan_config_file: /etc/netplan/60-ansible-config.yaml
      netplan_renderer: networkd
      netplan_configuration:
        network:
          version: 2
          ethernets:
            eth1:
              addresses:
                - 192.168.100.3{{groups["lb"].index(inventory_hostname)}}/24

# kubernetes setup phase
- hosts: control_plane:worker_node
  name: Kubernetes setup
  become: true
  tasks:
    - name: Add gpg key
      ansible.builtin.apt_key:
        url: https://packages.cloud.google.com/apt/doc/apt-key.gpg

    - name: Add k8s apt repository
      ansible.builtin.apt_repository:
        repo: deb http://apt.kubernetes.io/ kubernetes-xenial main

    - name: Update apt repository
      ansible.builtin.apt:
        update_cache: true

    - name: Install "kubeadm kubelet kubectl" packages
      ansible.builtin.apt:
        name: "{{ packages }}"
        state: present
      vars:
        packages:
          - kubeadm
          - kubelet
          - kubectl

    - name: Remove swapfile from /etc/fstab
      ansible.posix.mount:
        name: swap
        fstype: swap
        state: absent

    - name: Disable swap
      ansible.builtin.command: swapoff -a
      when: ansible_swaptotal_mb > 0
      changed_when: false

    - name: Update setting file
      ansible.builtin.template:
        src: ./ansible-template/10-kubeadm.conf.j2
        dest: /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        mode: "0644"

    - name: Restart kubelet.service
      ansible.builtin.systemd:
        name: kubelet
        daemon_reload: true
        state: restarted
        enabled: true

# kubernetes api lb setup phase
- hosts: lb
  name: Kubernetes api lb setup
  become: true
  tasks:
    - name: Install haproxy, keepalived
      ansible.builtin.apt:
        name: "{{ packages }}"
        state: present
      vars:
        packages:
          - haproxy
          - keepalived

    - name: Enable haproxy demon
      ansible.builtin.lineinfile:
        path: /etc/default/haproxy
        regexp: "^ENABLED="
        line: "ENABLED=1"

    - name: Send haproxy.cfg
      ansible.builtin.template:
        src: ansible-template/haproxy.cfg.j2
        dest: /etc/haproxy/haproxy.cfg
        mode: "0644"

    - name: Send keepalived.conf
      ansible.builtin.template:
        src: ansible-template/keepalived.conf.j2
        dest: /etc/keepalived/keepalived.conf
        mode: "0644"

    - name: Restart haproxy
      ansible.builtin.systemd:
        name: haproxy
        daemon_reload: true
        state: restarted
        enabled: true

    - name: Restart keepalived
      ansible.builtin.systemd:
        name: keepalived
        daemon_reload: true
        state: restarted
        enabled: true

# kubeadm setup phase
- hosts: delegate_plane
  name: Kubeadm setup
  any_errors_fatal: true
  become: true
  tasks:
    - name: Send kubeadm-config
      ansible.builtin.template:
        src: ansible-template/kubeadm-config.yml.j2
        dest: /tmp/kubeadm-config.yml
        mode: "0644"

    - name: Dry-run kubeadm init
      ansible.builtin.command: kubeadm init --dry-run
      register: kubeadm_dry_run
      changed_when: false
      failed_when: false

    - name: Run kubeadm init
      ansible.builtin.command: kubeadm init --config=/tmp/kubeadm-config.yml
      when: groups['control_plane'].index(inventory_hostname) == 0 and kubeadm_dry_run.rc == 0
      changed_when: false
      # skip init if already initialized

    # get cert
    - name: Get kubeadm cert
      ansible.builtin.command: kubeadm init phase upload-certs --upload-certs
      register: certs_raw
      changed_when: false

    - name: Set cert
      ansible.builtin.set_fact:
        certs: "{{ certs_raw.stdout_lines[2] }}"

    # get join command
    - name: Get join command
      ansible.builtin.command: kubeadm token create --print-join-command
      register: join_command_raw
      changed_when: false

    - name: Set join command
      ansible.builtin.set_fact:
        join_command: "{{ join_command_raw.stdout_lines[0] }}"

    - name: Create .kube directory for ictsc user
      ansible.builtin.file:
        path: /home/{{ item.name }}/.kube
        state: directory
        owner: "{{ item.name }}"
        mode: "0700"
      with_items:
        - "{{ users }}"

    - name: Copy admin.conf to ictsc kube config
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ item.name }}/.kube/config
        remote_src: true
        owner: "{{ item.name }}"
        mode: "0600"
      with_items:
        - "{{ users }}"

    - name: Create .kube directory for ubuntu user
      ansible.builtin.file:
        path: /home/ubuntu/.kube
        state: directory
        owner: ubuntu
        mode: "0700"

    - name: Copy admin.conf to ubuntu kube config
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/ubuntu/.kube/config
        remote_src: true
        owner: ubuntu
        mode: "0600"

# Helm install from apt
- hosts: delegate_plane
  name: Helm setup
  any_errors_fatal: true
  become: true
  tasks:
    - name: Add helm's official GPG key
      ansible.builtin.apt_key:
        url: https://helm.baltorepo.com/organization/signing.asc
        state: present

    - name: Add helm repository
      ansible.builtin.apt_repository:
        repo: deb https://baltocdn.com/helm/stable/debian/ all main
        state: present

    - name: Update apt repository
      ansible.builtin.apt:
        update_cache: true

    - name: Install helm
      ansible.builtin.apt:
        name: "{{ packages }}"
        state: present
      vars:
        packages:
          - helm

# CNI Install
# cilium install with BGP config
- hosts: delegate_plane
  name: Cilium setup
  any_errors_fatal: true
  tasks:
    - name: Send bgp-config
      ansible.builtin.template:
        src: ansible-template/bgp-config.yaml.j2
        dest: /tmp/bgp-config.yaml
        mode: "0644"

    - name: Apply bgp-config
      ansible.builtin.command: kubectl apply -f /tmp/bgp-config.yaml
      changed_when: false

    - name: Add Cilium chart repo
      ansible.builtin.shell: |
        helm repo add cilium https://helm.cilium.io/
        helm repo update
      changed_when: false

    - name: Deploy Cilium
      ansible.builtin.shell: |
        helm upgrade --install cilium cilium/cilium --version 1.12.6 \
        --namespace kube-system --set bgp.enabled=true --set bgp.announce.loadbalancerIP=true --set bgp.announce.podCIDR=true
      changed_when: false

    - name: Restart pods
      ansible.builtin.shell:
        executable: /bin/bash
        cmd: |
          set -o pipefail
          kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,HOSTNETWORK:.spec.hostNetwork \
          --no-headers=true | grep '<none>' | awk '{print "-n "$1" "$2}' | xargs -L 1 -r kubectl delete pod
      changed_when: false
      failed_when: false

# join other control_plane
- hosts: control_plane
  name: Join other control_plane
  become: true
  tasks:
    - name: Join cluster
      ansible.builtin.command:
        "{{ hostvars[groups['control_plane'][0]]['join_command'] }} --control_plane \
        --certificate-key {{ hostvars[groups['control_plane'][0]]['certs'] }}"
      changed_when: false
      failed_when: false
      when: groups['control_plane'].index(inventory_hostname) != 0

# join worker_node
- hosts: worker_node
  name: Join cluster
  become: true
  tasks:
    - name: Join cluster
      ansible.builtin.command: "{{ hostvars[groups['control_plane'][0]]['join_command'] }}"
      changed_when: true
      failed_when: false

# install argocd
- hosts: delegate_plane
  name: Install argo CD
  tasks:
    - name: Install argocd
      ansible.builtin.shell: |
        kubectl create namespace argocd
        kubectl apply -n argocd \
        -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
      changed_when: false
